{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 1. Imports</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javid/corrosion-detector/AP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, csv\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 2. Configuration & Paths</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "# Paths \n",
    "\n",
    "ROOT = \"../data\"\n",
    "\n",
    "# The following absolute path was used on the HPC server and is kept here\n",
    "# only for reference. It is NOT required to run this notebook locally.\n",
    "# ROOT = \"/home/javid/segmentation_resnet/data\"\n",
    "\n",
    "TRAIN_LIST = os.path.join(ROOT, \"train.txt\")\n",
    "VAL_LIST   = os.path.join(ROOT, \"val.txt\")\n",
    "TEST_LIST  = os.path.join(ROOT, \"test.txt\")\n",
    "\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 35   \n",
    "NUM_WORKERS = 4\n",
    "LR = 5e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 3. Model and Image Processor</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([1, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegFormer-B2 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "processor = SegformerImageProcessor(\n",
    "    do_resize=True,\n",
    "    size={\"height\": 512, \"width\": 512},\n",
    "    resample=Image.BILINEAR,\n",
    "    do_normalize=True\n",
    ")\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    \"nvidia/segformer-b2-finetuned-ade-512-512\",\n",
    "    num_labels=1,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"SegFormer-B2 loaded successfully.\")\n",
    "\n",
    "\n",
    "# The warning about newly initialized weights is expected.\n",
    "# The pretrained checkpoint uses 150 classes (ADE20K),\n",
    "# while this project performs binary segmentation (1 class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 4. Dataset Definition</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegFormerDataset(Dataset):\n",
    "    def __init__(self, list_path):\n",
    "        with open(list_path, \"r\") as f:\n",
    "            self.items = [line.strip().split() for line in f.readlines()]\n",
    "\n",
    "        self.mask_resize = transforms.Resize((512, 512), interpolation=Image.NEAREST)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, mask_path = self.items[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask  = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        mask = self.mask_resize(mask)\n",
    "        mask = (np.array(mask) > 127).astype(np.float32)\n",
    "        mask = torch.tensor(mask).unsqueeze(0)\n",
    "\n",
    "        encoded = processor(images=image, return_tensors=\"pt\")\n",
    "        img_tensor = encoded[\"pixel_values\"].squeeze(0)\n",
    "\n",
    "        return img_tensor, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 5. DataLoader Setup</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 571\n",
      "Val: 122\n",
      "Test: 123\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SegFormerDataset(TRAIN_LIST)\n",
    "val_dataset   = SegFormerDataset(VAL_LIST)\n",
    "test_dataset  = SegFormerDataset(TEST_LIST)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(\"Train:\", len(train_dataset))\n",
    "print(\"Val:\", len(val_dataset))\n",
    "print(\"Test:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 6. Loss Functions</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probas = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets == 1, probas, 1 - probas)\n",
    "        focal_weight = self.alpha * (1 - pt) ** self.gamma\n",
    "        loss = -focal_weight * torch.log(pt + 1e-8)\n",
    "        return loss.mean()\n",
    "\n",
    "bce_loss = FocalLoss(alpha=0.25, gamma=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, eps=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    inter = (pred * target).sum()\n",
    "    return 1 - (2 * inter + eps) / (pred.sum() + target.sum() + eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b>7. Evaluation Metrics</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(pred, true):\n",
    "    pred = pred.bool()\n",
    "    true = true.bool()\n",
    "    inter = (pred & true).sum().item()\n",
    "    union = (pred | true).sum().item()\n",
    "    return inter / union if union > 0 else 1.0\n",
    "\n",
    "def dice_score(pred, true):\n",
    "    pred = pred.bool()\n",
    "    true = true.bool()\n",
    "    inter = (pred & true).sum().item()\n",
    "    return (2 * inter) / (pred.sum().item() + true.sum().item() + 1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 8. Optimizer and Learning Rate Scheduler</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCHS,\n",
    "    eta_min=1e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 9. Output Directories</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: ../outputs/checkpoints/segformer_b2_finetuned\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"../outputs/checkpoints/segformer_b2_finetuned\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(save_dir, \"training_history.csv\")\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"epoch\", \"train_loss\", \"val_loss\", \"val_iou\", \"val_dice\"])\n",
    "\n",
    "print(\"Saving to:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 10. Training and Validation Loop</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1/35 =====\n",
      "Train Loss: 0.6169\n",
      "Val Loss:   0.5040\n",
      "Val IoU:    0.5550\n",
      "Val Dice:   0.6940\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 2/35 =====\n",
      "Train Loss: 0.4136\n",
      "Val Loss:   0.3547\n",
      "Val IoU:    0.6218\n",
      "Val Dice:   0.7465\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 3/35 =====\n",
      "Train Loss: 0.3067\n",
      "Val Loss:   0.2980\n",
      "Val IoU:    0.6592\n",
      "Val Dice:   0.7791\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 4/35 =====\n",
      "Train Loss: 0.2431\n",
      "Val Loss:   0.2901\n",
      "Val IoU:    0.6470\n",
      "Val Dice:   0.7690\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 5/35 =====\n",
      "Train Loss: 0.2105\n",
      "Val Loss:   0.2573\n",
      "Val IoU:    0.6786\n",
      "Val Dice:   0.7947\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 6/35 =====\n",
      "Train Loss: 0.1797\n",
      "Val Loss:   0.2532\n",
      "Val IoU:    0.6783\n",
      "Val Dice:   0.7946\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 7/35 =====\n",
      "Train Loss: 0.1644\n",
      "Val Loss:   0.2525\n",
      "Val IoU:    0.6734\n",
      "Val Dice:   0.7893\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 8/35 =====\n",
      "Train Loss: 0.1529\n",
      "Val Loss:   0.2538\n",
      "Val IoU:    0.6741\n",
      "Val Dice:   0.7902\n",
      "\n",
      "===== Epoch 9/35 =====\n",
      "Train Loss: 0.1367\n",
      "Val Loss:   0.2423\n",
      "Val IoU:    0.6902\n",
      "Val Dice:   0.8030\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 10/35 =====\n",
      "Train Loss: 0.1349\n",
      "Val Loss:   0.2359\n",
      "Val IoU:    0.6964\n",
      "Val Dice:   0.8075\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 11/35 =====\n",
      "LR ↓ to 3e-5\n",
      "Train Loss: 0.1271\n",
      "Val Loss:   0.2348\n",
      "Val IoU:    0.6982\n",
      "Val Dice:   0.8083\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 12/35 =====\n",
      "Train Loss: 0.1206\n",
      "Val Loss:   0.2338\n",
      "Val IoU:    0.6984\n",
      "Val Dice:   0.8093\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 13/35 =====\n",
      "Train Loss: 0.1152\n",
      "Val Loss:   0.2368\n",
      "Val IoU:    0.7004\n",
      "Val Dice:   0.8094\n",
      "\n",
      "===== Epoch 14/35 =====\n",
      "Train Loss: 0.1133\n",
      "Val Loss:   0.2372\n",
      "Val IoU:    0.6979\n",
      "Val Dice:   0.8091\n",
      "\n",
      "===== Epoch 15/35 =====\n",
      "Train Loss: 0.1112\n",
      "Val Loss:   0.2349\n",
      "Val IoU:    0.6990\n",
      "Val Dice:   0.8101\n",
      "\n",
      "===== Epoch 16/35 =====\n",
      "Train Loss: 0.1101\n",
      "Val Loss:   0.2289\n",
      "Val IoU:    0.7053\n",
      "Val Dice:   0.8146\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 17/35 =====\n",
      "Train Loss: 0.1064\n",
      "Val Loss:   0.2288\n",
      "Val IoU:    0.7063\n",
      "Val Dice:   0.8151\n",
      "Best model saved.\n",
      "\n",
      "===== Epoch 18/35 =====\n",
      "Train Loss: 0.1039\n",
      "Val Loss:   0.2323\n",
      "Val IoU:    0.7035\n",
      "Val Dice:   0.8132\n",
      "\n",
      "===== Epoch 19/35 =====\n",
      "Train Loss: 0.1021\n",
      "Val Loss:   0.2337\n",
      "Val IoU:    0.7028\n",
      "Val Dice:   0.8121\n",
      "\n",
      "===== Epoch 20/35 =====\n",
      "Train Loss: 0.1004\n",
      "Val Loss:   0.2340\n",
      "Val IoU:    0.7031\n",
      "Val Dice:   0.8127\n",
      "\n",
      "===== Epoch 21/35 =====\n",
      "LR ↓ to 1e-5\n",
      "Train Loss: 0.0978\n",
      "Val Loss:   0.2330\n",
      "Val IoU:    0.7022\n",
      "Val Dice:   0.8118\n",
      "\n",
      "===== Epoch 22/35 =====\n",
      "Train Loss: 0.0974\n",
      "Val Loss:   0.2331\n",
      "Val IoU:    0.7051\n",
      "Val Dice:   0.8143\n",
      "\n",
      "===== Epoch 23/35 =====\n",
      "Train Loss: 0.0949\n",
      "Val Loss:   0.2312\n",
      "Val IoU:    0.7068\n",
      "Val Dice:   0.8155\n",
      "\n",
      "===== Epoch 24/35 =====\n",
      "Train Loss: 0.0952\n",
      "Val Loss:   0.2296\n",
      "Val IoU:    0.7081\n",
      "Val Dice:   0.8166\n",
      "Early stopping triggered.\n",
      "\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "no_improve = 0\n",
    "early_stop_patience = 7\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n===== Epoch {epoch+1}/{EPOCHS} =====\")\n",
    "\n",
    "    # Adjust LR\n",
    "    if epoch == 10:\n",
    "        for g in optimizer.param_groups:\n",
    "            g[\"lr\"] = 3e-5\n",
    "        print(\"LR ↓ to 3e-5\")\n",
    "\n",
    "    if epoch == 20:\n",
    "        for g in optimizer.param_groups:\n",
    "            g[\"lr\"] = 1e-5\n",
    "        print(\"LR ↓ to 1e-5\")\n",
    "\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(pixel_values=imgs).logits\n",
    "\n",
    "        logits = F.interpolate(logits, size=(512,512), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        fl = bce_loss(logits, masks)\n",
    "        dl = dice_loss(logits, masks)\n",
    "        loss = fl + dl\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_losses, val_ious, val_dices = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "            logits = model(pixel_values=imgs).logits\n",
    "            logits = F.interpolate(logits, size=(512,512), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "            fl = bce_loss(logits, masks)\n",
    "            dl = dice_loss(logits, masks)\n",
    "            vloss = fl + dl\n",
    "            val_losses.append(vloss.item())\n",
    "\n",
    "            preds = (torch.sigmoid(logits) > 0.5).cpu()\n",
    "            masks_cpu = masks.cpu()\n",
    "\n",
    "            for p, t in zip(preds, masks_cpu):\n",
    "                val_ious.append(iou_score(p, t))\n",
    "                val_dices.append(dice_score(p, t))\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    avg_val_iou  = np.mean(val_ious)\n",
    "    avg_val_dice = np.mean(val_dices)\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"Val IoU:    {avg_val_iou:.4f}\")\n",
    "    print(f\"Val Dice:   {avg_val_dice:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"best_model.pth\"))\n",
    "        print(\"Best model saved.\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"\\nTraining completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b>12. Test Set Evaluation</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TEST RESULTS =====\n",
      "Test Loss: 0.2323145622735828\n",
      "Test IoU:  0.7234881565825485\n",
      "Test Dice: 0.8231578442212272\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_losses, test_ious, test_dices = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, masks in test_loader:\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "        logits = model(pixel_values=imgs).logits\n",
    "        logits = F.interpolate(logits, size=(512,512), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        fl = bce_loss(logits, masks)\n",
    "        dl = dice_loss(logits, masks)\n",
    "        loss = fl + dl\n",
    "        test_losses.append(loss.item())\n",
    "\n",
    "        preds = (torch.sigmoid(logits) > 0.5).cpu()\n",
    "        masks_cpu = masks.cpu()\n",
    "\n",
    "        for p, t in zip(preds, masks_cpu):\n",
    "            test_ious.append(iou_score(p, t))\n",
    "            test_dices.append(dice_score(p, t))\n",
    "\n",
    "print(\"\\n===== TEST RESULTS =====\")\n",
    "print(\"Test Loss:\", np.mean(test_losses))\n",
    "print(\"Test IoU: \", np.mean(test_ious))\n",
    "print(\"Test Dice:\", np.mean(test_dices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "----------\n",
    "---------\n",
    "# <b> 13. Saving Test Predictions</b> \n",
    "\n",
    "--------------\n",
    "----------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction folder: ../outputs/predictions/segformer_b2_finetuned_predictions\n",
      "All predictions saved.\n"
     ]
    }
   ],
   "source": [
    "pred_dir = \"../outputs/predictions/segformer_b2_finetuned_predictions\"\n",
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "print(\"Prediction folder:\", pred_dir)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (imgs, masks) in enumerate(test_loader):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "\n",
    "        logits = model(pixel_values=imgs).logits\n",
    "        logits = F.interpolate(logits, size=(512,512), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float().cpu().numpy()[0,0]\n",
    "\n",
    "        pred_img = (preds * 255).astype(np.uint8)\n",
    "        pred_pil = Image.fromarray(pred_img)\n",
    "\n",
    "        img_path = test_dataset.items[idx][0]\n",
    "        base_name = os.path.basename(img_path)\n",
    "        name_no_ext = os.path.splitext(base_name)[0]\n",
    "\n",
    "        pred_pil.save(os.path.join(pred_dir, f\"{name_no_ext}_pred.png\"))\n",
    "\n",
    "print(\"All predictions saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AP)",
   "language": "python",
   "name": "ap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
